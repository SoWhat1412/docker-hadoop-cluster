{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "# Configure Spark to use a local master\n",
    "# launcher.master = \"local[*]\" # tested to work\n",
    "launcher.master = \"yarn\"\n",
    "launcher.packages = \"neo4j-contrib:neo4j-spark-connector:2.1.0-M4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://hadoop-master:8088/proxy/application_1551686720681_0005\n",
       "SparkContext available as 'sc' (version = 2.0.0, master = yarn, app id = application_1551686720681_0005)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yarn\n"
     ]
    }
   ],
   "source": [
    "println(sc.master)\n",
    "// val rdd = sc.parallelize(0 to 999)\n",
    "// rdd.takeSample(false, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.neo4j.spark._\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.neo4j.spark._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neo: org.neo4j.spark.Neo4j = org.neo4j.spark.Neo4j@6ccf3165\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val neo = Neo4j(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = Neo4jRDD partitions Partitions(1,9223372036854775807,9223372036854775807,None) MATCH (n:Person) return id(n) as id using Map()\n",
       "res1: Long = 100\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = neo.cypher(\"MATCH (n:Person) return id(n) as id\").loadRowRdd\n",
    "rdd.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[String] = Array(id)\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first.schema.fieldNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Double = 66.5\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo.cypher(\"MATCH (n:Person) RETURN id(n)\").loadRdd[Long].mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Long = 10\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo.cypher(\"MATCH (n:Person) WHERE n.id <= {maxId} RETURN n.id\").param(\"maxId\", 10).loadRowRdd.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "32: error: overloaded method value nodes with alternatives:",
     "output_type": "error",
     "traceback": [
      "<console>:32: error: overloaded method value nodes with alternatives:",
      "  (cypher: String,params: Map[String,Any])org.neo4j.spark.Neo4j <and>",
      "  => org.neo4j.spark.Neo4j.Query",
      " cannot be applied to (String)",
      "       neo.nodes(\"MATCH (n:Person) RETURN id(n) SKIP {_skip} LIMIT {_limit}\").partitions(4).batch(25).loadRowRdd.count",
      "           ^",
      ""
     ]
    }
   ],
   "source": [
    "neo.nodes(\"MATCH (n:Person) RETURN id(n) SKIP {_skip} LIMIT {_limit}\").partitions(4).batch(25).loadRowRdd.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Long = 80\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo.pattern(\"Person\",Seq(\"KNOWS\"),\"Person\").rows(80).batch(21).loadNodeRdds.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: Long = 1000\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo.pattern(\"Person\",Seq(\"KNOWS\"),\"Person\").partitions(12).batch(100).loadRelRdd.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [id: bigint]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = neo.pattern(\"Person\",Seq(\"KNOWS\"),\"Person\").partitions(12).batch(100).loadDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: Array[org.apache.spark.sql.Row] = Array([19], [29], [83], [55], [51], [104], [73], [44], [77], [17], [47], [34], [95], [40], [56], [89], [94], [27], [116], [84], [82], [80], [106], [49], [23], [30], [79], [109], [58], [90], [98], [81], [93], [86], [108], [96], [26], [22], [31], [71], [69], [60], [100], [105], [101], [62], [75], [88], [70], [91], [114], [37], [53], [38], [25], [92], [39], [45], [99], [107], [32], [35], [50], [36], [76], [43], [52], [42], [113], [111], [18], [21], [64], [103], [41], [57], [48], [24], [115], [66], [97], [110], [20], [28], [67], [59], [61], [33], [65], [78], [46], [87], [102], [68], [54], [74], [112], [72], [63], [85])\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
