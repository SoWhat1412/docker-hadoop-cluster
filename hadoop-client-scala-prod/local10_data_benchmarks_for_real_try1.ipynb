{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "local09 error is due to either, and is uncaught:\n",
    "- java.lang.AssertionError\n",
    "- java.io.IOException: No space left on device\n",
    "\n",
    "Changed to catch NonFatal. Moved docker runtime dir, now it has large amount of disk (before it had 60G)\n",
    "And trying again\n",
    "\n",
    "https://stackoverflow.com/questions/29744462/the-difference-between-nonfatal-and-exception-in-scala\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://10.100.34.19:9988 neo4j, testing w full data, around 75g\n",
    "\n",
    "https://stackoverflow.com/questions/44590284/number-of-executors-in-spark-local-mode\n",
    "\n",
    "in local mode spark UI shows one driver and all cores, and none of the executors\n",
    "\n",
    "\n",
    "- Neo4jExperiment(sc, 1200, 125000), running around ~4h and errors to (spark.driver.memory=1g)\n",
    "\n",
    "        org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
    "        \n",
    "        Name: org.apache.spark.SparkException\n",
    "        Message: Job aborted due to stage failure: Task 32 in stage 1291.0 failed 1 times, most recent failure: Lost task 32.0 in stage 1291.0 (TID 61352, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 457952 ms\n",
    "        \n",
    "        Exception in thread \"Executor task launch worker-82\" java.lang.OutOfMemoryError: Java heap space\n",
    "\n",
    "- Trying with spark.driver.memory=45g, just in case, although error was executor memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:33:45.149750Z",
     "start_time": "2019-05-07T09:33:03.358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will be printed.\n"
     ]
    }
   ],
   "source": [
    "%showtypes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:33:49.640035Z",
     "start_time": "2019-05-07T09:33:46.964Z"
    }
   },
   "outputs": [],
   "source": [
    "import org.neo4j.spark._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{SQLContext, DataFrame, Row, SaveMode}\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.graphx.lib._\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.rdd.{RDD}\n",
    "import scala.util.control.NonFatal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting spark resources\n",
    "- https://stackoverflow.com/questions/29940711/apache-spark-setting-executor-instances-does-not-change-the-executors\n",
    "- https://stackoverflow.com/questions/32621990/what-are-workers-executors-cores-in-spark-standalone-cluster\n",
    "- https://medium.com/@thejasbabu/spark-under-the-hood-partition-d386aaaa26b7\n",
    "- https://stackoverflow.com/questions/24622108/apache-spark-the-number-of-cores-vs-the-number-of-executors\n",
    "\n",
    "\n",
    "\n",
    "### executors\n",
    "    kg@bigdata-009>\n",
    "    CPU(s):       64\n",
    "    Mem:          252G\n",
    "    \n",
    "     <name>yarn.nodemanager.resource.memory-mb</name>\n",
    "     <value>64960</value>\n",
    "\n",
    "     <name>yarn.scheduler.maximum-allocation-vcores</name>\n",
    "     <value>360</value>\n",
    "     \n",
    "     <name>yarn.nodemanager.resource.cpu-vcores</name>\n",
    "     <value>36</value>\n",
    "     \n",
    "- You can assign the number of cores per executor with `--executor-cores`\n",
    "- `yarn.nodemanager.resource.memory-mb` needs to be larger than `--executor-memory`\n",
    "- Setting `spark.executor.*` only applied to `yarn` and not local\n",
    "- seems better to have 3 or 4 executors per node, instead of 1 executors per node\n",
    "- on each node leave ~10% memory and cpu for yarn and other overheads\n",
    "- TODO: unsolved whether spark.executor.cores refers to core or vcore, can test by setting spark.executor.cores to be large number, eg 340, and if executor still can be allocated then it refers to vcore \n",
    "\n",
    "- yarn.scheduler.maximum-allocation-vcores controls the maximum vcores that any submitted job can request. yarn.nodemanager.resource.cpu-vcores, on the other hand, controls how many vcores can be scheduled on a particular NodeManager instance. \n",
    "\n",
    "### partitions\n",
    "- The recommend number of partitions is around 3 or 4 times the number of CPUs in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:03.809738Z",
     "start_time": "2019-05-07T09:34:00.132Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark web UI: http://10.100.34.19:4040/ (or 4041...)\n",
      "(spark.externalBlockStore.folderName,spark-b7535801-8d31-4c0a-99bc-54e30e45d95e)\n",
      "(spark.executor.memory,45g)\n",
      "(spark.neo4j.bolt.url,bolt://neo4j:neo4j0fcredithc@10.100.34.19:9989)\n",
      "(spark.yarn.queue,kg)\n",
      "(spark.driver.extraClassPath,file:///usr/local/spark/jars-sd/neo4j-spark-connector-full-2.0.0-M2-s_1.6.1.jar,file:///usr/local/spark/jars-sd/netty-all-4.1.8.Final.jar,file:///usr/local/spark/jars-sd/neo4j-java-driver-1.7.2.jar,file:///usr/local/spark/jars-sd/graphframes-0.5.0-spark1.6-s_2.10.jar,file:///usr/local/spark/jars-sd/scala-logging-api_2.10-2.1.2.jar,file:///usr/local/spark/jars-sd/scala-logging-slf4j_2.10-2.1.2.jar,file:///usr/local/spark/jars-sd/scala-reflect-2.10.4.jar,file:///usr/local/spark/jars-sd/slf4j-api-1.7.7.jar)\n",
      "(spark.app.name,local09)\n",
      "(spark.executor.id,driver)\n",
      "(spark.driver.extraJavaOptions,-Xms100G -Xmx400G -Dlog4j.logLevel=info)\n",
      "(spark.executor.instances,8)\n",
      "(spark.neo4j.bolt.password,neo4j0fcredithc)\n",
      "(spark.driver.host,10.100.34.19)\n",
      "(spark.driver.memory,45g)\n",
      "(spark.executor.cores,4)\n",
      "(spark.app.id,local-1557225075442)\n",
      "(spark.neo4j.bolt.user,neo4j)\n",
      "(spark.executor.port,9993)\n",
      "(spark.fileserver.port,9994)\n",
      "(spark.jars,file:///usr/local/spark/jars-sd/neo4j-spark-connector-full-2.0.0-M2-s_1.6.1.jar,file:///usr/local/spark/jars-sd/netty-all-4.1.8.Final.jar,file:///usr/local/spark/jars-sd/neo4j-java-driver-1.7.2.jar,file:///usr/local/spark/jars-sd/graphframes-0.5.0-spark1.6-s_2.10.jar,file:///usr/local/spark/jars-sd/scala-logging-api_2.10-2.1.2.jar,file:///usr/local/spark/jars-sd/scala-logging-slf4j_2.10-2.1.2.jar,file:///usr/local/spark/jars-sd/scala-reflect-2.10.4.jar,file:///usr/local/spark/jars-sd/slf4j-api-1.7.7.jar,file:/opt/conda/share/jupyter/kernels/apache_toree_scala/lib/toree-assembly-0.1.0-incubating.jar)\n",
      "(spark.master,local[38])\n",
      "(spark.replClassServer.port,9995)\n",
      "(spark.submit.deployMode,client)\n",
      "(spark.driver.port,9992)\n",
      "(spark.broadcast.port,9991)\n",
      "(spark.driver.blockManager.port,9990)\n"
     ]
    }
   ],
   "source": [
    "// sc.stop() // see kernel.json, see \"__TOREE_OPTS__\": \"--nosparkcontext\"\n",
    "// spark.driver.memory=45g. Is set in docker/conf/spark-defaults.conf\n",
    "val conf = new SparkConf().set(\"spark.app.name\",\"local09\").set(\"spark.master\",\"local[38]\").set(\"spark.executor.instances\",\"8\").set(\"spark.executor.cores\",\"4\").set(\"spark.executor.memory\",\"45g\")\n",
    "\n",
    "val sc = new SparkContext(conf)\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "import sqlContext.implicits._\n",
    "\n",
    "// val neo = Neo4j(sc)\n",
    "\n",
    "println(\"Spark web UI: \" + \"http://10.100.34.19:4040/ (or 4041...)\") //spark web UI\n",
    "sc.getConf.getAll.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:04.821143Z",
     "start_time": "2019-05-07T09:34:00.841Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pickleThis[A](sc:SparkContext, dataToSave:A, schemaString:String, savePath:String) : String = {\n",
    "    val dataToSaveReady = dataToSave match {\n",
    "      case dataToSave:RDD[Row] => dataToSave // val qq : RDD[Row] = loaded_df.rdd // the reverse transformation\n",
    "      case dataToSave:Array[Row] => sc.parallelize(dataToSave.toList) // val qq = loaded_df.collect // the reverse transformation\n",
    "// DOESNT WORK because it intercepts List[Array[Any]]\n",
    "// case dataToSave:List[Array[String]] => sc.parallelize(dataToSave.map(p => Row(p: _*))) \n",
    "      case dataToSave:List[Array[_]] => {\n",
    "          val tmp = dataToSave.map(row => row.map(el => el.toString))\n",
    "          sc.parallelize(tmp.map(p => Row(p: _*))) \n",
    "      }\n",
    "      case _ => throw new Exception(\"Wrong argument type\")\n",
    "    }\n",
    "\n",
    "  val schema =\n",
    "    StructType(\n",
    "      schemaString.split(\" \").map(fieldName => StructField(fieldName, StringType, true)))\n",
    "\n",
    "  val dfToSave = sqlContext.createDataFrame(dataToSaveReady, schema)\n",
    "\n",
    "  dfToSave.write.mode(\"overwrite\").save(savePath)\n",
    "  println(\"data overwritten\")\n",
    "    \n",
    "  return s\"\"\"val loaded_df = sqlContext.read.load(\\\"$savePath\\\")\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:04.836127Z",
     "start_time": "2019-05-07T09:34:01.655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// // val query = \"MATCH p=()-[r:Person_relation]->() RETURN count(r)\"\n",
    "// // val query = \"MATCH (n:Person) RETURN count(n)\"\n",
    "\n",
    "// val query = s\"\"\"MATCH (a) WITH DISTINCT LABELS(a) AS temp, COUNT(a) AS tempCnt\n",
    "// UNWIND temp AS label\n",
    "// RETURN label, SUM(tempCnt) AS cnt\"\"\"\n",
    "\n",
    "// val cursor = Executor.execute(sc, query, Map((\"\",\"\")))\n",
    "// val response = cursor.rows.toList\n",
    "\n",
    "// val label_counts = response.sortWith(_(1).asInstanceOf[Long] > _(1).asInstanceOf[Long])\n",
    "// pickleThis(sc, label_counts, \"label count_n\", \"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/label_counts.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:04.848200Z",
     "start_time": "2019-05-07T09:34:01.857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// val label_counts_df = sqlContext.read.load(\"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/label_counts.pickle\")\n",
    "// label_counts_df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:04.859001Z",
     "start_time": "2019-05-07T09:34:02.537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// val label_rel_counts = label_counts.map( row => {\n",
    "//     val str = row(0)\n",
    "//     val query = s\"MATCH (n:$str)-[r]-() return COUNT(r)\"\n",
    "//     val cursor = Executor.execute(sc, query, Map((\"\",\"\")))\n",
    "//     val response = cursor.rows.toList\n",
    "//     row :+ response(0)(0)\n",
    "// })\n",
    "// pickleThis(sc, label_rel_counts, \"label count_n count_r\", \"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/label_rel_counts.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:07.487150Z",
     "start_time": "2019-05-07T09:34:03.633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "var label_rel_counts_df = sqlContext.read.load(\"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/label_rel_counts.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### casting columns to the right types, since we didnt save it right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:09.825194Z",
     "start_time": "2019-05-07T09:34:06.768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- count_n: integer (nullable = true)\n",
      " |-- count_r: integer (nullable = true)\n",
      "\n",
      "+-----------------+--------+---------+\n",
      "|            label| count_n|  count_r|\n",
      "+-----------------+--------+---------+\n",
      "|         HC_repay| 1963947|        0|\n",
      "|            Phone|22173769| 51227904|\n",
      "|      Mobilephone|18822274| 42658529|\n",
      "|          Address| 7976921| 18842999|\n",
      "|       HC_presona|    8279|  5504220|\n",
      "|     Bank_account| 1868242|  2801423|\n",
      "|        HC_client| 4112976| 70850813|\n",
      "|           Person|19342651|140069325|\n",
      "|      HC_contract| 2185195|  2180338|\n",
      "|          ID_card| 4194817|  9779910|\n",
      "|     HC_blacklist|   94850|        0|\n",
      "|         Landline| 3351495|  8569375|\n",
      "|          HC_role|     206|        0|\n",
      "|     HC_intopiece| 5308780| 80801782|\n",
      "|    HC_client_mes| 6216762| 10353541|\n",
      "|HC_intopiece_link|15040832|        0|\n",
      "|         HC_staff|  177505|   718550|\n",
      "|          Company| 2892023| 21315735|\n",
      "|            Email| 1137400|  1169363|\n",
      "|      HC_graylist|   55464|        0|\n",
      "+-----------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_rel_counts_df = label_rel_counts_df.withColumn(\"count_n\", label_rel_counts_df(\"count_n\").cast(\"int\"))\n",
    "label_rel_counts_df = label_rel_counts_df.withColumn(\"count_r\", label_rel_counts_df(\"count_r\").cast(\"int\"))\n",
    "label_rel_counts_df.printSchema\n",
    "label_rel_counts_df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:14.889164Z",
     "start_time": "2019-05-07T09:34:13.785Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "// class Neo4jExperiment\n",
    "import org.neo4j.spark.{Neo4j, Neo4jGraph}\n",
    "import org.apache.spark.graphx.{Graph, VertexId}\n",
    "\n",
    "class Neo4jExperiment(val sc:SparkContext, val partitions:Int=12, val batch:Int=125) {\n",
    "    val neo = Neo4j(sc)\n",
    "    var neo4j : Neo4j = null.asInstanceOf[Neo4j]\n",
    "    var graph : Graph[Long, String] = null.asInstanceOf[Graph[Long, String]]\n",
    "    var graphSaveThis : Graph[VertexId,String] = null.asInstanceOf[Graph[VertexId, String]]\n",
    "    \n",
    "    def get_count_load_time(label:String) : Double = {\n",
    "        println(\"label: \" ++ label)\n",
    "        println(\"partitions: \" ++ partitions.toString)\n",
    "        println(\"batch: \" ++ batch.toString)\n",
    "        \n",
    "        val t_start = System.currentTimeMillis()\n",
    "        try {\n",
    "            neo4j = neo.rels(s\"MATCH (n:$label)-[r]-(m) RETURN id(n) as src, id(m) as dst, type(r) as value SKIP {_skip} LIMIT {_limit}\").partitions(partitions).batch(batch)\n",
    "            graph = neo4j.loadGraph[Long,String]\n",
    "            println(\"get_count_load_time ending\")\n",
    "            (System.currentTimeMillis() - t_start)/1000d\n",
    "        } catch {\n",
    "          case NonFatal(e) => {\n",
    "              println(\"==\" * 20 ++ \"get_count_load_time_SDERRORSTART\")\n",
    "              println(\"==\" * 20)\n",
    "              e.printStackTrace\n",
    "              println(\"==\" * 20 ++ \"get_count_load_time_SDERROREND\")\n",
    "              println(\"==\" * 20)\n",
    "              (System.currentTimeMillis() - t_start)/1000d + 1e8 // 1e8 seconds = 3 years\n",
    "          }\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    def get_count_n_time(label:String) : Double = {\n",
    "        val t_start = System.currentTimeMillis()\n",
    "        try {\n",
    "            println(graph.vertices.count)\n",
    "            (System.currentTimeMillis() - t_start)/1000d\n",
    "        } catch {\n",
    "          case NonFatal(e) => {\n",
    "              println(\"==\" * 20 ++ \"get_count_n_time_SDERRORSTART\")\n",
    "              println(\"==\" * 20)\n",
    "              e.printStackTrace\n",
    "              println(\"==\" * 20 ++ \"get_count_n_time_SDERROREND\")\n",
    "              println(\"==\" * 20)\n",
    "              (System.currentTimeMillis() - t_start)/1000d + 1e8 // 1e8 seconds = 3 years\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def get_count_r_time(label:String) : Double = {        \n",
    "        val t_start = System.currentTimeMillis()\n",
    "        try {\n",
    "            println(graph.edges.count)\n",
    "            (System.currentTimeMillis() - t_start)/1000d\n",
    "        } catch {\n",
    "          case NonFatal(e) => {\n",
    "              println(\"==\" * 20 ++ \"get_count_r_time_SDERRORSTART\")\n",
    "              println(\"==\" * 20)\n",
    "              e.printStackTrace\n",
    "              println(\"==\" * 20 ++ \"get_count_r_time_SDERROREND\")\n",
    "              println(\"==\" * 20)\n",
    "              (System.currentTimeMillis() - t_start)/1000d + 1e8 // 1e8 seconds = 3 years\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def get_count_cc_time(label:String) : Double = {\n",
    "        val t_start = System.currentTimeMillis()\n",
    "        try {\n",
    "            // Find the connected components\n",
    "            graphSaveThis = graph.connectedComponents()\n",
    "            println(\"get_count_cc_time ending\")\n",
    "            (System.currentTimeMillis() - t_start)/1000d\n",
    "        } catch {\n",
    "          case NonFatal(e) => {\n",
    "              println(\"==\" * 20 ++ \"get_count_cc_time_SDERRORSTART\")\n",
    "              println(\"==\" * 20)\n",
    "              e.printStackTrace\n",
    "              println(\"==\" * 20 ++ \"get_count_cc_time_SDERROREND\")\n",
    "              println(\"==\" * 20)\n",
    "              (System.currentTimeMillis() - t_start)/1000d + 1e8 // 1e8 seconds = 3 years\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def get_count_save_time(label:String) : Double = {\n",
    "        val t_start = System.currentTimeMillis()\n",
    "        try {\n",
    "            val return_val = Neo4jGraph.saveGraph(sc, graphSaveThis, \"sdComponent\")\n",
    "            println(\"saveGraph: \" ++ return_val.toString) // how many nodes has been written\n",
    "            (System.currentTimeMillis() - t_start)/1000d\n",
    "        } catch {\n",
    "          case NonFatal(e) => {\n",
    "              println(\"==\" * 20 ++ \"get_count_save_time_SDERRORSTART\")\n",
    "              println(\"==\" * 20)\n",
    "              e.printStackTrace\n",
    "              println(\"==\" * 20 ++ \"get_count_save_time_SDERROREND\")\n",
    "              println(\"==\" * 20)\n",
    "              (System.currentTimeMillis() - t_start)/1000d + 1e8 // 1e8 seconds = 3 years\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-07T09:34:17.152416Z",
     "start_time": "2019-05-07T09:34:16.113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------+----------+--------------+\n",
      "|        label| count_n|  count_r|batch_size|partition_size|\n",
      "+-------------+--------+---------+----------+--------------+\n",
      "|   HC_presona|    8279|  5504220|     10000|           551|\n",
      "|     HC_staff|  177505|   718550|     10000|            72|\n",
      "|        Email| 1137400|  1169363|     10000|           117|\n",
      "| Bank_account| 1868242|  2801423|     10000|           281|\n",
      "|  HC_contract| 2185195|  2180338|     10000|           219|\n",
      "|      Company| 2892023| 21315735|     10000|          2132|\n",
      "|     Landline| 3351495|  8569375|     10000|           857|\n",
      "|    HC_client| 4112976| 70850813|     10000|          7086|\n",
      "|      ID_card| 4194817|  9779910|     10000|           978|\n",
      "| HC_intopiece| 5308780| 80801782|     10000|          8081|\n",
      "|HC_client_mes| 6216762| 10353541|     10000|          1036|\n",
      "|      Address| 7976921| 18842999|     10000|          1885|\n",
      "|  Mobilephone|18822274| 42658529|     10000|          4266|\n",
      "|       Person|19342651|140069325|     10000|         14007|\n",
      "|        Phone|22173769| 51227904|     10000|          5123|\n",
      "+-------------+--------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// select a batch_size small enough for spark.executor.memory=45g, apparently 125000 was too big\n",
    "var df = label_rel_counts_df.filter($\"count_r\" > 0).sort($\"count_n\")   // $\"count_n\".desc\n",
    "val batch_size = 10000\n",
    "df = df.withColumn(\"batch_size\", lit(batch_size) ).withColumn(\"partition_size\", ceil($\"count_r\"/batch_size) )\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: HC_presona\n",
      "partitions: 551\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "5490054\n",
      "5504220\n",
      "get_count_cc_time ending\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 28236 in stage 3034.0 failed 1 times, most recent failure: Lost task 28236.0 in stage 3034.0 (TID 64978, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:84)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 31 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1088)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1082)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:33)\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:88)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:84)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 31 more\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: HC_staff\n",
      "partitions: 72\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "514692\n",
      "718550\n",
      "get_count_cc_time ending\n",
      "saveGraph: (514692,0)\n",
      "label: Email\n",
      "partitions: 117\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "2285911\n",
      "1169363\n",
      "get_count_cc_time ending\n",
      "saveGraph: (2285911,0)\n",
      "label: Bank_account\n",
      "partitions: 281\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "3643679\n",
      "2801423\n",
      "get_count_cc_time ending\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 28221 in stage 25079.0 failed 1 times, most recent failure: Lost task 28221.0 in stage 25079.0 (TID 144341, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:84)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 31 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1088)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1082)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:33)\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:88)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:84)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 31 more\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: HC_contract\n",
      "partitions: 219\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "========================================get_count_n_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 31 in stage 25090.0 failed 1 times, most recent failure: Lost task 31.0 in stage 25090.0 (TID 144593, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_n_time(<console>:57)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "========================================get_count_n_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_r_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 33 in stage 25093.0 failed 1 times, most recent failure: Lost task 33.0 in stage 25093.0 (TID 144636, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.EdgeRDDImpl.count(EdgeRDDImpl.scala:89)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_r_time(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:75)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "========================================get_count_r_time_SDERROREND\n",
      "========================================\n",
      "get_count_cc_time ending\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 28226 in stage 25177.0 failed 1 times, most recent failure: Lost task 28226.0 in stage 25177.0 (TID 176370, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:84)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 31 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1088)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1082)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply$mcD$sp(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1.apply(DoubleRDDFunctions.scala:34)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.DoubleRDDFunctions.sum(DoubleRDDFunctions.scala:33)\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:88)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:84)\n",
      "\tat org.neo4j.spark.Neo4jGraph$$anonfun$5.apply(Neo4jGraph.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 31 more\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: Company\n",
      "partitions: 2132\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "========================================get_count_n_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 25188.0 failed 1 times, most recent failure: Lost task 22.0 in stage 25188.0 (TID 176615, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_n_time(<console>:57)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "========================================get_count_n_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_r_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 25191.0 failed 1 times, most recent failure: Lost task 17.0 in stage 25191.0 (TID 176654, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.EdgeRDDImpl.count(EdgeRDDImpl.scala:89)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_r_time(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:75)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "========================================get_count_r_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_cc_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25195.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25195.0 (TID 176676, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:125)\n",
      "\tat org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
      "\tat org.apache.spark.graphx.GraphOps.connectedComponents(GraphOps.scala:417)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_cc_time(<console>:92)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:76)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "========================================get_count_cc_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "java.lang.NullPointerException\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:79)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: Landline\n",
      "partitions: 857\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "========================================get_count_n_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 23 in stage 25210.0 failed 1 times, most recent failure: Lost task 23.0 in stage 25210.0 (TID 176970, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_n_time(<console>:57)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "========================================get_count_n_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_r_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 29 in stage 25213.0 failed 1 times, most recent failure: Lost task 29.0 in stage 25213.0 (TID 177016, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.EdgeRDDImpl.count(EdgeRDDImpl.scala:89)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_r_time(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:75)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "========================================get_count_r_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_cc_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 25217.0 failed 1 times, most recent failure: Lost task 17.0 in stage 25217.0 (TID 177043, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:125)\n",
      "\tat org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
      "\tat org.apache.spark.graphx.GraphOps.connectedComponents(GraphOps.scala:417)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_cc_time(<console>:92)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:76)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "========================================get_count_cc_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "java.lang.NullPointerException\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:79)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: HC_client\n",
      "partitions: 7086\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "========================================get_count_n_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 21 in stage 25232.0 failed 1 times, most recent failure: Lost task 21.0 in stage 25232.0 (TID 177298, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_n_time(<console>:57)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "========================================get_count_n_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_r_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 26 in stage 25235.0 failed 1 times, most recent failure: Lost task 26.0 in stage 25235.0 (TID 177381, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.EdgeRDDImpl.count(EdgeRDDImpl.scala:89)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_r_time(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:75)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "========================================get_count_r_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_cc_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25239.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25239.0 (TID 177395, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:125)\n",
      "\tat org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
      "\tat org.apache.spark.graphx.GraphOps.connectedComponents(GraphOps.scala:417)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_cc_time(<console>:92)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:76)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "========================================get_count_cc_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "java.lang.NullPointerException\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:79)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: ID_card\n",
      "partitions: 978\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "========================================get_count_n_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 25254.0 failed 1 times, most recent failure: Lost task 35.0 in stage 25254.0 (TID 177700, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_n_time(<console>:57)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "========================================get_count_n_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_r_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 25257.0 failed 1 times, most recent failure: Lost task 7.0 in stage 25257.0 (TID 177712, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.EdgeRDDImpl.count(EdgeRDDImpl.scala:89)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_r_time(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:75)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "========================================get_count_r_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_cc_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25261.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25261.0 (TID 177745, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:125)\n",
      "\tat org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
      "\tat org.apache.spark.graphx.GraphOps.connectedComponents(GraphOps.scala:417)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_cc_time(<console>:92)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:76)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "========================================get_count_cc_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "java.lang.NullPointerException\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:79)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: HC_intopiece\n",
      "partitions: 8081\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "========================================get_count_n_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 25276.0 failed 1 times, most recent failure: Lost task 15.0 in stage 25276.0 (TID 177992, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_n_time(<console>:57)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "========================================get_count_n_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_r_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 25279.0 failed 1 times, most recent failure: Lost task 4.0 in stage 25279.0 (TID 178059, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.EdgeRDDImpl.count(EdgeRDDImpl.scala:89)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_r_time(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:75)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "========================================get_count_r_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_cc_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 25283.0 failed 1 times, most recent failure: Lost task 25.0 in stage 25283.0 (TID 178119, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:125)\n",
      "\tat org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
      "\tat org.apache.spark.graphx.GraphOps.connectedComponents(GraphOps.scala:417)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_cc_time(<console>:92)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:76)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "========================================get_count_cc_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "java.lang.NullPointerException\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:79)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: HC_client_mes\n",
      "partitions: 1036\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "========================================get_count_n_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 25298.0 failed 1 times, most recent failure: Lost task 2.0 in stage 25298.0 (TID 178366, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_n_time(<console>:57)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 34 more\n",
      "========================================get_count_n_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_r_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 25301.0 failed 1 times, most recent failure: Lost task 24.0 in stage 25301.0 (TID 178455, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.EdgeRDDImpl.count(EdgeRDDImpl.scala:89)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_r_time(<console>:74)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:75)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:268)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 37 more\n",
      "========================================get_count_r_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_cc_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 25305.0 failed 1 times, most recent failure: Lost task 24.0 in stage 25305.0 (TID 178494, localhost): org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:125)\n",
      "\tat org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
      "\tat org.apache.spark.graphx.GraphOps.connectedComponents(GraphOps.scala:417)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_cc_time(<console>:92)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:76)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.neo4j.driver.v1.exceptions.ServiceUnavailableException: Unable to process request: Cannot assign requested address\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:138)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.startSocketClient(SocketConnection.java:89)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnection.<init>(SocketConnection.java:64)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.createConnection(SocketConnector.java:77)\n",
      "\tat org.neo4j.driver.internal.net.SocketConnector.connect(SocketConnector.java:50)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:204)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool$ConnectionSupplier.get(SocketConnectionPool.java:186)\n",
      "\tat org.neo4j.driver.internal.net.pooling.BlockingPooledConnectionQueue.acquire(BlockingPooledConnectionQueue.java:93)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquireConnection(SocketConnectionPool.java:137)\n",
      "\tat org.neo4j.driver.internal.net.pooling.SocketConnectionPool.acquire(SocketConnectionPool.java:76)\n",
      "\tat org.neo4j.driver.internal.DirectConnectionProvider.acquireConnection(DirectConnectionProvider.java:45)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.acquireConnection(NetworkSession.java:347)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:103)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:93)\n",
      "\tat org.neo4j.driver.internal.NetworkSession.run(NetworkSession.java:80)\n",
      "\tat org.neo4j.spark.Executor$.execute(Neo4j.scala:385)\n",
      "\tat org.neo4j.spark.Neo4jRDD.compute(Neo4j.scala:431)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "Caused by: java.net.BindException: Cannot assign requested address\n",
      "\tat sun.nio.ch.Net.connect0(Native Method)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:454)\n",
      "\tat sun.nio.ch.Net.connect(Net.java:446)\n",
      "\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\n",
      "\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:102)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.connect(ChannelFactory.java:64)\n",
      "\tat org.neo4j.driver.internal.net.ChannelFactory.create(ChannelFactory.java:41)\n",
      "\tat org.neo4j.driver.internal.net.SocketClient.start(SocketClient.java:124)\n",
      "\t... 28 more\n",
      "========================================get_count_cc_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "java.lang.NullPointerException\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:79)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n",
      "label: Address\n",
      "partitions: 1885\n",
      "batch: 10000\n",
      "get_count_load_time ending\n",
      "19965757\n",
      "18842999\n",
      "========================================get_count_cc_time_SDERRORSTART\n",
      "========================================\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 240 in stage 131403.0 failed 1 times, most recent failure: Lost task 240.0 in stage 131403.0 (TID 616279, localhost): java.io.IOException: No space left on device\n",
      "\tat java.io.FileOutputStream.writeBytes(Native Method)\n",
      "\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n",
      "\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n",
      "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
      "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
      "\tat org.xerial.snappy.SnappyOutputStream.flush(SnappyOutputStream.java:319)\n",
      "\tat org.apache.spark.io.SnappyOutputStreamWrapper.flush(CompressionCodec.scala:209)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.flush(ObjectOutputStream.java:1823)\n",
      "\tat java.io.ObjectOutputStream.flush(ObjectOutputStream.java:719)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.flush(JavaSerializer.scala:57)\n",
      "\tat org.apache.spark.storage.DiskBlockObjectWriter.commitAndClose(DiskBlockObjectWriter.scala:130)\n",
      "\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:661)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
      "\tat scala.Option.foreach(Option.scala:236)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1025)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1007)\n",
      "\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
      "\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:143)\n",
      "\tat org.apache.spark.graphx.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n",
      "\tat org.apache.spark.graphx.GraphOps.connectedComponents(GraphOps.scala:417)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_cc_time(<console>:92)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:76)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.IOException: No space left on device\n",
      "\tat java.io.FileOutputStream.writeBytes(Native Method)\n",
      "\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n",
      "\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n",
      "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
      "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
      "\tat org.xerial.snappy.SnappyOutputStream.flush(SnappyOutputStream.java:319)\n",
      "\tat org.apache.spark.io.SnappyOutputStreamWrapper.flush(CompressionCodec.scala:209)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.flush(ObjectOutputStream.java:1823)\n",
      "\tat java.io.ObjectOutputStream.flush(ObjectOutputStream.java:719)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.flush(JavaSerializer.scala:57)\n",
      "\tat org.apache.spark.storage.DiskBlockObjectWriter.commitAndClose(DiskBlockObjectWriter.scala:130)\n",
      "\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:661)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
      "\t... 3 more\n",
      "========================================get_count_cc_time_SDERROREND\n",
      "========================================\n",
      "========================================get_count_save_time_SDERRORSTART\n",
      "========================================\n",
      "java.lang.NullPointerException\n",
      "\tat org.neo4j.spark.Neo4jGraph$.saveGraph(Neo4jGraph.scala:79)\n",
      "\tat $line68.$read$$iwC$$iwC$Neo4jExperiment.get_count_save_time(<console>:110)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:77)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
      "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
      "\tat $line80.$read$$iwC$$iwC$$iwC.<init>(<console>:107)\n",
      "\tat $line80.$read$$iwC$$iwC.<init>(<console>:109)\n",
      "\tat $line80.$read$$iwC.<init>(<console>:111)\n",
      "\tat $line80.$read.<init>(<console>:113)\n",
      "\tat $line80.$read$.<init>(<console>:117)\n",
      "\tat $line80.$read$.<clinit>(<console>)\n",
      "\tat $line80.$eval$.<init>(<console>:7)\n",
      "\tat $line80.$eval$.<clinit>(<console>)\n",
      "\tat $line80.$eval.$print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
      "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
      "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
      "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
      "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
      "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "========================================get_count_save_time_SDERROREND\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: error: \n",
       "     while compiling: <console>\n",
       "        during phase: jvm\n",
       "     library version: version 2.10.5\n",
       "    compiler version: version 2.10.5\n",
       "  reconstructed args: -classpath file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunec.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/zipfs.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunpkcs11.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/dnsns.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/jaccess.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/cldrdata.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/nashorn.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/icedtea-sound.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunjce_provider.jar:file:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/localedata.jar:file:/home/jovyan/work/hadoop-client-scala-prod/file:file:/usr/local/spark/jars-sd/neo4j-spark-connector-full-2.0.0-M2-s_1.6.1.jar,file:file:/usr/local/spark/jars-sd/netty-all-4.1.8.Final.jar,file:file:/usr/local/spark/jars-sd/neo4j-java-driver-1.7.2.jar,file:file:/usr/local/spark/jars-sd/graphframes-0.5.0-spark1.6-s_2.10.jar,file:file:/usr/local/spark/jars-sd/scala-logging-api_2.10-2.1.2.jar,file:file:/usr/local/spark/jars-sd/scala-logging-slf4j_2.10-2.1.2.jar,file:file:/usr/local/spark/jars-sd/scala-reflect-2.10.4.jar,file:file:/usr/local/spark/jars-sd/slf4j-api-1.7.7.jar:file:/usr/local/spark/conf/:file:/usr/local/spark/lib/spark-assembly-1.6.1-hadoop2.6.0.jar:file:/usr/local/spark/lib/datanucleus-core-3.2.10.jar:file:/usr/local/spark/lib/datanucleus-api-jdo-3.2.6.jar:file:/usr/local/spark/lib/datanucleus-rdbms-3.2.9.jar:file:/usr/local/hadoop/etc/hadoop/:file:/opt/conda/share/jupyter/kernels/apache_toree_scala/lib/toree-assembly-0.1.0-incubating.jar:file:/usr/local/spark/jars-sd/neo4j-spark-connector-full-2.0.0-M2-s_1.6.1.jar:file:/usr/local/spark/jars-sd/netty-all-4.1.8.Final.jar:file:/usr/local/spark/jars-sd/neo4j-java-driver-1.7.2.jar:file:/usr/local/spark/jars-sd/graphframes-0.5.0-spark1.6-s_2.10.jar:file:/usr/local/spark/jars-sd/scala-logging-api_2.10-2.1.2.jar:file:/usr/local/spark/jars-sd/scala-logging-slf4j_2.10-2.1.2.jar:file:/usr/local/spark/jars-sd/scala-reflect-2.10.4.jar:file:/usr/local/spark/jars-sd/slf4j-api-1.7.7.jar\n",
       "\n",
       "  last tree to typer: term value \n",
       "              symbol: variable value in object $eval (flags: <mutable> <triedcooking> private[this])\n",
       "   symbol definition: private[this] var value: Throwable\n",
       "                 tpe: <notype>\n",
       "       symbol owners: variable value -> object $eval -> package $line81\n",
       "      context owners: object $eval -> package $line81\n",
       "\n",
       "== Enclosing template or block ==\n",
       "\n",
       "Template( // val <local $eval>: <notype> in object $eval, tree.tpe=type\n",
       "  \"java.lang.Object\" // parents\n",
       "  ValDef(\n",
       "    private\n",
       "    \"_\"\n",
       "    <tpt>\n",
       "    <empty>\n",
       "  )\n",
       "  // 5 statements\n",
       "  ValDef( // private[this] var value: Throwable in object $eval\n",
       "    private <mutable> <local> <defaultinit> <triedcooking>\n",
       "    \"value \"\n",
       "    <tpt> // tree.tpe=Throwable\n",
       "    <empty>\n",
       "  )\n",
       "  DefDef( // def value(): Throwable in object $eval\n",
       "    <method> <accessor> <defaultinit> <triedcooking>\n",
       "    \"value\"\n",
       "    []\n",
       "    List(Nil)\n",
       "    <tpt> // tree.tpe=Throwable\n",
       "    $eval.this.\"value \" // private[this] var value: Throwable in object $eval, tree.tpe=Throwable\n",
       "  )\n",
       "  DefDef( // def value_=(x$1: Throwable): Unit in object $eval\n",
       "    <method> <accessor> <defaultinit> <triedcooking>\n",
       "    \"value_$eq\"\n",
       "    []\n",
       "    // 1 parameter list\n",
       "    ValDef( // x$1: Throwable\n",
       "      <param> <synthetic> <triedcooking>\n",
       "      \"x$1\"\n",
       "      <tpt> // tree.tpe=Throwable\n",
       "      <empty>\n",
       "    )\n",
       "    <tpt> // tree.tpe=Unit\n",
       "    Assign( // tree.tpe=Unit\n",
       "      $eval.this.\"value \" // private[this] var value: Throwable in object $eval, tree.tpe=Throwable\n",
       "      \"x$1\" // x$1: Throwable, tree.tpe=Throwable\n",
       "    )\n",
       "  )\n",
       "  DefDef( // def set(x: Object): Unit in object $eval\n",
       "    <method>\n",
       "    \"set\"\n",
       "    []\n",
       "    // 1 parameter list\n",
       "    ValDef( // x: Object\n",
       "      <param> <triedcooking>\n",
       "      \"x\"\n",
       "      <tpt> // tree.tpe=Object\n",
       "      <empty>\n",
       "    )\n",
       "    <tpt> // tree.tpe=Unit\n",
       "    Apply( // def value_=(x$1: Throwable): Unit in object $eval, tree.tpe=Unit\n",
       "      $eval.this.\"value_$eq\" // def value_=(x$1: Throwable): Unit in object $eval, tree.tpe=(x$1: Throwable)Unit\n",
       "      Apply( // final def $asInstanceOf[T0 >: ? <: ?](): T0 in class Object, tree.tpe=Throwable\n",
       "        TypeApply( // final def $asInstanceOf[T0 >: ? <: ?](): T0 in class Object, tree.tpe=()Throwable\n",
       "          \"x\".\"$asInstanceOf\" // final def $asInstanceOf[T0 >: ? <: ?](): T0 in class Object, tree.tpe=[T0 >: ? <: ?]()T0\n",
       "          <tpt> // tree.tpe=Throwable\n",
       "        )\n",
       "        Nil\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  DefDef( // def <init>(): type in object $eval\n",
       "    <method>\n",
       "    \"<init>\"\n",
       "    []\n",
       "    List(Nil)\n",
       "    <tpt> // tree.tpe=type\n",
       "    Block( // tree.tpe=Unit\n",
       "      Apply( // def <init>(): Object in class Object, tree.tpe=Object\n",
       "        $eval.super.\"<init>\" // def <init>(): Object in class Object, tree.tpe=()Object\n",
       "        Nil\n",
       "      )\n",
       "      ()\n",
       "    )\n",
       "  )\n",
       ")\n",
       "\n",
       "== Expanded type of tree ==\n",
       "\n",
       "<notype>\n",
       "\n",
       "uncaught exception during compilation: java.lang.AssertionError\n",
       "org.apache.spark.SparkException: Job aborted due to stage failure: Task 31 in stage 131581.0 failed 1 times, most recent failure: Lost task 31.0 in stage 131581.0 (TID 616384, localhost): java.io.IOException: No space left on device\n",
       "\tat java.io.FileOutputStream.writeBytes(Native Method)\n",
       "\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n",
       "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
       "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
       "\tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n",
       "\tat java.io.FilterOutputStream.close(FilterOutputStream.java:158)\n",
       "\tat org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$writeIndexFileAndCommit$2.apply$mcV$sp(IndexShuffleBlockResolver.scala:151)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1259)\n",
       "\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.writeIndexFileAndCommit(IndexShuffleBlockResolver.scala:150)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:128)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "\tSuppressed: java.io.IOException: No space left on device\n",
       "\t\tat java.io.FileOutputStream.writeBytes(Native Method)\n",
       "\t\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n",
       "\t\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
       "\t\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
       "\t\tat java.io.FilterOutputStream.close(FilterOutputStream.java:158)\n",
       "\t\tat java.io.FilterOutputStream.close(FilterOutputStream.java:159)\n",
       "\t\t... 11 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
       "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
       "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
       "\tat scala.Option.foreach(Option.scala:236)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:212)\n",
       "\tat org.apache.spark.sql.execution.Limit.executeCollect(basicOperators.scala:165)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeCollectPublic(SparkPlan.scala:174)\n",
       "\tat org.apache.spark.sql.DataFrame$$anonfun$org$apache$spark$sql$DataFrame$$execute$1$1.apply(DataFrame.scala:1499)\n",
       "\tat org.apache.spark.sql.DataFrame$$anonfun$org$apache$spark$sql$DataFrame$$execute$1$1.apply(DataFrame.scala:1499)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)\n",
       "\tat org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:2086)\n",
       "\tat org.apache.spark.sql.DataFrame.org$apache$spark$sql$DataFrame$$execute$1(DataFrame.scala:1498)\n",
       "\tat org.apache.spark.sql.DataFrame.org$apache$spark$sql$DataFrame$$collect(DataFrame.scala:1505)\n",
       "\tat org.apache.spark.sql.DataFrame$$anonfun$head$1.apply(DataFrame.scala:1375)\n",
       "\tat org.apache.spark.sql.DataFrame$$anonfun$head$1.apply(DataFrame.scala:1374)\n",
       "\tat org.apache.spark.sql.DataFrame.withCallback(DataFrame.scala:2099)\n",
       "\tat org.apache.spark.sql.DataFrame.head(DataFrame.scala:1374)\n",
       "\tat org.apache.spark.sql.DataFrame.head(DataFrame.scala:1383)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:69)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:67)\n",
       "\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n",
       "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:83)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:85)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:87)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:89)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:91)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n",
       "\tat $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n",
       "\tat $iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n",
       "\tat $iwC$$iwC$$iwC.<init>(<console>:107)\n",
       "\tat $iwC$$iwC.<init>(<console>:109)\n",
       "\tat $iwC.<init>(<console>:111)\n",
       "\tat <init>(<console>:113)\n",
       "\tat .<init>(<console>:117)\n",
       "\tat .<clinit>(<console>)\n",
       "\tat .<init>(<console>:7)\n",
       "\tat .<clinit>(<console>)\n",
       "\tat $print(<console>)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "\tat org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "\tat org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "\tat org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "Caused by: java.io.IOException: No space left on device\n",
       "\tat java.io.FileOutputStream.writeBytes(Native Method)\n",
       "\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n",
       "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
       "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
       "\tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n",
       "\tat java.io.FilterOutputStream.close(FilterOutputStream.java:158)\n",
       "\tat org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$writeIndexFileAndCommit$2.apply$mcV$sp(IndexShuffleBlockResolver.scala:151)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1259)\n",
       "\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.writeIndexFileAndCommit(IndexShuffleBlockResolver.scala:150)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:128)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
       "\t... 3 more\n",
       "\tSuppressed: java.io.IOException: No space left on device\n",
       "\t\tat java.io.FileOutputStream.writeBytes(Native Method)\n",
       "\t\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n",
       "\t\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
       "\t\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
       "\t\tat java.io.FilterOutputStream.close(FilterOutputStream.java:158)\n",
       "\t\tat java.io.FilterOutputStream.close(FilterOutputStream.java:159)\n",
       "\t\t... 11 more\n",
       "StackTrace: "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = label_rel_counts_df.filter($\"count_r\" > 0).sort($\"count_n\")   // $\"count_n\".desc\n",
    "// val batch_size = 10000 // defined in cell above\n",
    "df = df.withColumn(\"batch_size\", lit(batch_size) ).withColumn(\"partition_size\", ceil($\"count_r\"/batch_size) )\n",
    "\n",
    "var count_load_time:Seq[(String, Double)] = Seq.empty\n",
    "var count_n_time:Seq[(String, Double)] = Seq.empty\n",
    "var count_r_time:Seq[(String, Double)] = Seq.empty\n",
    "var count_cc_time:Seq[(String, Double)] = Seq.empty\n",
    "var count_save_time:Seq[(String, Double)] = Seq.empty\n",
    "\n",
    "df.collect.foreach(row => {\n",
    "    val label = row(0).toString\n",
    "    val partition_size:Int = df.filter($\"label\" === s\"$label\").select(\"partition_size\").head.get(0).toString.toInt\n",
    "    val batch_size:Int = df.filter($\"label\" === s\"$label\").select(\"batch_size\").head.get(0).toString.toInt\n",
    "    \n",
    "    val neo4jExperiment = new Neo4jExperiment(sc, partition_size, batch_size) // new Neo4jExperiment(sc, 12, 125) // new Neo4jExperiment(sc, 1200, 125000)\n",
    "    count_load_time = count_load_time :+ (label, neo4jExperiment.get_count_load_time(label))\n",
    "    count_n_time = count_n_time :+ (label, neo4jExperiment.get_count_n_time(label))\n",
    "    count_r_time = count_r_time :+ (label, neo4jExperiment.get_count_r_time(label))\n",
    "    count_cc_time = count_cc_time :+ (label, neo4jExperiment.get_count_cc_time(label))\n",
    "    count_save_time = count_save_time :+ (label, neo4jExperiment.get_count_save_time(label))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// putting results in the df\n",
    "val dftemp = count_load_time.toDF(\"label\",\"count_load_time\")\n",
    "df = df.join(dftemp, Seq(\"label\"), \"left\")\n",
    "\n",
    "val dftemp = count_n_time.toDF(\"label\",\"count_n_time\")\n",
    "df = df.join(dftemp, Seq(\"label\"), \"left\")\n",
    "\n",
    "val dftemp = count_r_time.toDF(\"label\",\"count_r_time\")\n",
    "df = df.join(dftemp, Seq(\"label\"), \"left\")\n",
    "\n",
    "val dftemp = count_cc_time.toDF(\"label\",\"count_cc_time\")\n",
    "df = df.join(dftemp, Seq(\"label\"), \"left\")\n",
    "\n",
    "val dftemp = count_save_time.toDF(\"label\",\"count_save_time\")\n",
    "df = df.join(dftemp, Seq(\"label\"), \"left\")\n",
    "\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").save(\"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/local09_sdout.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val local08_sdout = sqlContext.read.load(\"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/local09_sdout.pickle\")\n",
    "local08_sdout.printSchema\n",
    "local08_sdout.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// // pattern is using `id(n)` if node property is set to null, like example below\n",
    "// val t_start = System.currentTimeMillis()\n",
    "\n",
    "// // val g = Neo4jGraph.loadGraph(sc, \"Person\", Seq(\"Person_relation\"), \"Person\")\n",
    "// val graph = neo.pattern((\"Person\",null),(\"Person_relation\",null),(\"Person\",null)).partitions(40).batch(850000).loadGraph[Long,Long]\n",
    "\n",
    "// val t_end = System.currentTimeMillis()\n",
    "// println(\"Elapsed time: \" + (t_end - t_start)/1000d + \"s\")\n",
    "\n",
    "// g.vertices.take(5)\n",
    "\n",
    "// val udfSquared = udf((num: Int) => {\n",
    "//     num - 9999\n",
    "//   }\n",
    "// )\n",
    "// df.withColumn(\"count_n2\", udfSquared($\"count_n\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// // Pickling example\n",
    "// label_counts.foreach(row => println(row.deep.mkString(\"\\t\\t\")))\n",
    "// val label_counts_casted:List[(String,String)] = label_counts.map(el => (el(0).toString,el(1).toString))\n",
    "// val label_counts_df = sc.parallelize(label_counts_casted,1).toDS().toDF()\n",
    "// label_counts_df.write.mode(\"overwrite\").save(\"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/label_counts_df.pickle\")\n",
    "// // val label_counts_df = sqlContext.read.load(\"file:///home/jovyan/work/hadoop-client-scala-prod/pickles/label_counts_df.pickle\")\n",
    "// label_counts_df.show\n",
    "// label_counts_df.collect.foreach(el => println(el(0), el(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// turning df to Array[Seq[String]] with null values\n",
    "// df.collect.map(row => row.toSeq.map(el => Option(el).getOrElse(\"null\").toString))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Toree - Scala (local[20])",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
